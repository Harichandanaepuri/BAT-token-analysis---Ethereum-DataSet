---
title: "Project1"
author: "Akhila Perabe, Harichandana Epuri"
date: "31 October 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(error=TRUE)
library("fitdistrplus")
library("dplyr")
library("exptest")
library("ggpubr")

library(sqldf)
```
##Ethereum
Ethereum is a public opensource blockchain-based distributed computing platform featuring smart contract functionality which are the applications that run exactly as programmed without any possibility of downtime fraud or third-party interference.These applications run on a enormously powerful shared global infrastructure  which is a custom built blockchain that can move value around and represent the ownership of property.
This enables developers to create markets, store registries of debts or promises, move funds in accordance with instructions given long in the past and many other things that have not been invented yet, all without a middleman or counterparty risk.

##ERC20

ERC stands for Ethereum Request for Comments. It an official protocol for proposing improvements to the Ethereum(ETH) network. '20' is the unique proposal ID number.It defines a set of rules which need to be met in order for a token to be accepted and called an 'ERC20 Token'. The standard rules apply to all ERC20 Tokens since these rules are required to interact with each other on the Ethereum network. These tokens are blockchain assets that can have value and can be sent and received, like Bitcoin, Litecoin, Ethereum, or any other cryptocurrency. 

##Primary Token (BAT)

BAT stands for Basic Attention Token which radically improves the efficiency of digital advertising by creating a new token that can be exchanged between publishers, advertisers, and users. It all happens on the Ethereum blockchain.The token can be used to obtain a variety of advertising and attention-based services on the BAT platform. The utility of the token is based on user attention, which simply means a person's focused mental engagement.Its total supply is 1,500,000,000 and the decimal count is 18.

<h3>Question 1: Find the distribution of how many times a user 1 - buys, 2 - sells a token. Which discrete distribution type fits these distributions best? Estimate distribution parameters.
</h3>


In this we are trying to find a distribution of the number of times a user buys and sells a token.

##About the Dataset

As per the instructions provided we have chosen the 12th biggest token from the provided dataset, which is for Basic Attention Token (BAT). The ethereum token graph file for BAT, networkbatTX.txt is loaded from the local system and used for processing.


```{r}
data <- read.csv(file="C:/Users/haric/Downloads/Ethereum token graphs/networkbatTX.txt", header=FALSE, sep=" ")
colnames(data)<- c("fromNodeID","toNodeID","UnixTime","tokenAmount")
head(data)
```

 This dataset has a total of `r nrow(data)` number of token transactions.

## Preprocessing the dataset
For BAT, the total supply of tokens is $15*10^8$ and has decimal subunits of $10^{18}$

```{r}
totalSupply<-15*10^8*10^18
```
So any transactions with token value over $`r totalSupply`$ needs to eliminated from the dataset.

```{r}
removed<-data[(data$tokenAmount>totalSupply),]
data<-data[(data$tokenAmount<=totalSupply),]
```

By this constraint, we have removed `r nrow(removed)` transactions from the dataset which are outlier transactions. The remaining dataset will be used for processing in the next steps.

The following are the outliers being eliminated:
```{r}
removed
```

## Distribution for selling token

Frequency of sales for each user:
```{r}
sellingcount<-count(data,data$fromNodeID)
colnames(sellingcount)<- c("sellerID","frequency")
sellingcount
```

Sale counts frequency table for the token:
```{r}
sellingcountfrequency<-count(sellingcount,sellingcount$frequency)
colnames(sellingcountfrequency)<-c("Numberofsales","frequency_of_no_of_sales")
sellingcountfrequency
```

Bar plot for Sales Count against its frequency is show below:

We are using the barplot function to plot the sales count against its frequency.

```{r}
barplot(sellingcountfrequency$frequency_of_no_of_sales,names.arg =sellingcountfrequency$Numberofsales,ylab="Frequency_no_of_sales", xlab = "Number of sales" , xlim = c(0,30))
```

Verifying if the distribution is a weibull distribution:

To fit the distribution, we are using fitdist function which is present in the fitdistrplus package.

```{r}
fit_selling <- fitdist(sellingcountfrequency$frequency_of_no_of_sales, "weibull")
fit_selling
plot(fit_selling)
```

The theoretical and empirical graph for weibull distribution does not match. So not a weibull distribution.

Now verifying if the distribution is a exponential distribution:
```{r}
exptest::atkinson.exp.test(sellingcountfrequency$frequency_of_no_of_sales)
```

The p-value above is too lower than 0.05 so not an exponential distribution.

Verifying if the distribution is a poisson distribution:
```{r}
fit_selling <- fitdist(sellingcountfrequency$frequency_of_no_of_sales, "pois")
fit_selling
plot(fit_selling)
```

This shows that theoretical and empirical graph matches for poisson distribution, so we can conclude that the given distribution is a poisson distribution.

###### Mean : `r mean(sellingcountfrequency$frequency_of_no_of_sales)`
###### Standard Deviation : `r sd(sellingcountfrequency$frequency_of_no_of_sales)`

## Distribution for buying token

Frequency of buying for each user:
```{r}
buyingcount<-count(data,data$toNodeID)
colnames(buyingcount)<- c("buyerID","frequency")
head(buyingcount)
```

Buy counts frequency table for the token:

```{r}
buyingcountfrequency<-count(buyingcount,buyingcount$frequency)
colnames(buyingcountfrequency)<-c("Numberofbuys","frequency_of_no_of_buys")
buyingcountfrequency
```

Bar plot for Buy Count against its frequency is show below:

We are using the barplot function to plot the sales count against its frequency.
```{r}
barplot(buyingcountfrequency$frequency_of_no_of_buys,names.arg =buyingcountfrequency$Numberofbuys,ylab="Frequency_no_of_buys", xlab = "Number of buys", xlim=c(0,20))
```


Verifying if the distribution is a weibull distribution:


To fit the distribution, we are using fitdist function which is present in the fitdistrplus package.

```{r}
fit_buying <- fitdist(buyingcountfrequency$frequency_of_no_of_buys, "weibull")
fit_buying
plot(fit_buying)
```

The theoretical and empirical graph for weibull distribution does not match. So not a weibull distribution.

Now verifying if the distribution is a exponential distribution:
```{r}
exptest::atkinson.exp.test(buyingcountfrequency$frequency_of_no_of_buys)
```

The p-value above is too lower than 0.05 so not an exponential distribution.

Verifying if the distribution is a poisson distribution:
```{r}
fit_buying  <- fitdist(buyingcountfrequency$frequency_of_no_of_buys, "pois")
fit_buying
plot(fit_buying)
```

## Findings

This shows that theoretical and empirical graph matches for poisson distribution, so we can conclude that the given distribution is a poisson distribution.

###### Mean : `r mean(buyingcountfrequency$frequency_of_no_of_buys)`
###### Standard Deviation : `r sd(buyingcountfrequency$frequency_of_no_of_buys)`



<h3>
Question 2:How can we create layers of transactions with increasing amounts? This descriptive statistic is similar to bin selection in histograms. For example, we could choose layer1 as those transactions that involve 0.01Ã—maxt in amount. Find a good value for the number of layers and justify your choice.Find an algorithm to compute the correlation of price data with each of the layers (hint: start by looking at Pearson correlation).
</h3>

##About the Dataset

```{r}
data <- read.csv(file="C:/Users/haric/Downloads/Ethereum token graphs/networkbatTX.txt", header=FALSE, sep=" ")
colnames(data)<- c("fromNodeID","toNodeID","UnixTime","tokenAmount")
```

The token price dataset for BAT is loaded from the local system. This dataset will have open, close, high and low token price for each day.
```{r}
priceDataset <- read.csv(file="C:/Users/haric/Downloads/tokenPrices/bat", header=TRUE, sep="\t")
```

## Preprocessing the dataset
For BAT, the total supply of tokens is $15*10^8$ and has decimal subunits of $10^{18}$

```{r}
totalSupply<-15*10^8*10^18
```
So any transactions with token value over $`r totalSupply`$ needs to eliminated from the dataset.

```{r}
removed<-data[(data$tokenAmount>totalSupply),]
data<-data[(data$tokenAmount<=totalSupply),]
```

By this constraint, we have removed `r nrow(removed)` transactions f

```{r}
priceSd<-sd(data$tokenAmount)
priceMean<-mean(data$tokenAmount)
removedOutliers<-data[abs(data$tokenAmount-priceMean)>2*priceSd,]
data<-data[abs(data$tokenAmount-priceMean)<=2*priceSd,]
data["Date"]<-apply(data, 1, function(x) format(as.Date(as.POSIXct(x["UnixTime"], origin="1970-01-01")), "%m/%d/%Y"))
```

Further we need to remove the outlier transactions, which are too far away from the price mean. We consider transactions priced 2*StandardDeviation away from the price mean as outlier data here and eliminate them.

Thus `r nrow(removedOutliers)` number of transactions are removed from the data set by this constraint.

## Layering of token transactions based on amount.
We are considering the correlation between the number of transactions in a day with the change in the token price (High-Low). The correlation algorithms we have considered are pearson, spearman and kendall.

We started by creating 10 layers with the following price ranges.

$[ min-0.00005*max, 0.00005*max-0.0001*max, 0.0001*max-0.0005*max, 0.0005*max-0.001*max, 0.001*max-0.0015*max, 0.0015*max-0.004*max, 0.004*max-0.007*max, 0.007*max-0.01*max, 0.01*max-0.05*max, 0.05*max-max ]$

Using this price range the corresponding correlation we obtained were:

$[0.3506054, 0.3445820, 0.3853420, 0.4763306, 0.5697537, 0.5814955, 0.6011818, 0.5183419, 0.4622298, 0.2926601]$

By further analysis on the above results, we decided to merge a few layers which have no significant difference in their correlation. Thus we have created 6 layers with the price ranges given below.

$[ min-0.0005*max, 0.0005*max-0.001*max, 0.001*max-0.007*max, 0.007*max-0.01*max, 0.01*max-0.05*max, 0.05*max-max ]$

We are using adding cor() function to calculate the correlation.
```{r}
min<-min(data$tokenAmount)
max<-max(data$tokenAmount)
layers<-c(min, 0.0005*max, 0.001*max, 0.007*max, 0.01*max, 0.05*max, max)
cor_arr<-c()

i<-2
while(i <= length(layers)) {
  minThreshold<-layers[i-1]
  maxThreshold<-layers[i]

  layerData<-data[(data$tokenAmount>=minThreshold),]
  layerData<-layerData[(layerData$tokenAmount<maxThreshold),]

  counts<-count(layerData,layerData$Date)
  colnames(counts)<- c("Date","frequency")

   cat('\n')  
   cat("Layer ", i-1, "\n") 
   cat('\n')  
   i<-i+1

   barplot(counts$frequency,names.arg =counts$Date,ylab="Frequency of transactions", xlab = "Date")

  layerPrices<-merge(x = counts, y = priceDataset, by = "Date", x.all=TRUE)
  cor_arr<-c(cor_arr, (cor(layerPrices$frequency, layerPrices$High-layerPrices$Low, method = c("spearman"))))
}

```

Using pearson algorithm, we obtained the correlation for the six layers as:

[ 0.3844061, 0.4763306, 0.6162456, 0.5183419, 0.4622298, 0.2926601 ]

Using spearman algorithm, we obtained the correlation as below, which is better than pearson algorithm.

[ `r cor_arr` ]

##Findings

We see that the correlation between the token price change in the day (High-Low) with the number of transactions for the day is maximum in the price range [`r 0.001*max` - `r 0.007*max`] with correlation coefficient 0.628.

This means that the transactions priced in the mid range depends significantly on the token price. The extreme lower and higher priced transactions does not significantly depend on the token price of the day but might depend on some other factors.

##References

1. https://www.ethereum.org/

2. https://support.exodus.io/article/108-what-is-an-erc20-token-and-does-exodus-support-it

3. https://basicattentiontoken.org/faq/



```{r}
UniqueBuyerscount<-count(data,data$Date)
colnames(UniqueBuyerscount)<-c("Date","Frequency")

```
```{r}
shift <- function(x, n){
  c(x[-(seq(n))], rep(NA, n))
}

priceDataset["shiftedlow"] <- shift(priceDataset$Low, 1)
```

```{r}
finalTable<-merge(x =UniqueBuyerscount, y = priceDataset, by = "Date", x.all=TRUE)
finalTable["price_return"]<-(finalTable$Low-finalTable$shiftedlow)/(finalTable$shiftedlow)
```
```{r}
lmHeight = lm(finalTable$price_return~finalTable$Volume data = finalTable) #Create the linear regression
summary(lmHeight) 
```



